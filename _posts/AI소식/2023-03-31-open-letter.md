---
title: "[AI소식] Pause Giant AI Experiments: An Open Letter"
last_modified_at: 2023-03-31
categories:
  - AI소식
tags:
  - AI
excerpt: "Pause Giant AI Experiments"
use_math: true
classes: wide
---

3월 29일, 비영리 단체 Future of Life Institute의 홈페이지에 하나의 Open Letter ([링크](https://futureoflife.org/open-letter/pause-giant-ai-experiments/))가 올라왔다. 

이 Open Letter의 제목은 **Pause Giant AI Experiments**, 즉 거대 AI에 대한 실험을 멈추라는 것이다. 

구체적으로 요청하는 내용은 다음과 같다.  

> We call on all AI labs to immediately pause for at least 6 months the training of AI systems more powerful than GPT-4.  
> 우리는 모든 AI 연구소에게 GPT-4보다 강력한 AI 시스템의 학습을 즉시 6개월 이상 중단할 것을 요청합니다.

이 Open Letter는 올라온 지 얼마 지나지 않아 많은 관심을 불러왔는데, OpenAI의 창립자인 **일론 머스크**가 이 Open Letter를 서명했기 때문이다. 일론 머스크 이외에도 DeepMind를 포함한 수많은 AI 연구소의 과학자들과 IT 업계 CEO들, AI 분야의 교수들이 서명하였다. (서명한 사람들은 Open Letter 링크에서 확인 가능)

이 Open Letter의 전체 내용은 아래와 같다. (번역본 / 원본은 Open Letter 링크 참고)

> 인간 수준의 지능을 가진 AI 시스템은 광범위한 연구와 최고의 AI 연구소들이 인정하는 것처럼, 사회와 인류에 깊은 위험을 불러일으킬 수 있습니다. Asilomar AI 원칙에서도 언급되었듯이, 고도의 AI는 지구 생명의 역사에서 깊은 변화를 일으킬 수 있으므로, 적절한 주의와 자원으로 계획되고 관리되어야 합니다. 하지만 최근 몇 달간 AI 연구소들은 아무도, 심지어 그들의 창조자들도 이해, 예측 또는 신뢰할 수 없는 점점 더 강력한 디지털 마인드를 개발하고 배포하기 위한 무제한 경쟁 속에 빠져들고 있습니다.  
>  
> 현대의 AI 시스템은 이제 일반적인 작업에서 인간과 경쟁할 수 있게 되어 있으며, 우리는 스스로에게 다음과 같은 질문을 해야 합니다. 기계가 우리의 정보 채널을 프로파간다와 거짓 정보로 물들이도록 놔둬야 할까요? 충족감을 주는 일도 포함하여 모든 일자리를 자동화해야 할까요? 우리를 추월하고 지능적으로 능가하며 우리를 대체할 비인간적인 마음을 개발해야 할까요? 우리 문명을 제어 잃을 위험을 무릅쓰고 있을까요? 이러한 결정은 비선출 기술 리더에게 위임해서는 안 됩니다. 강력한 AI 시스템은 그들의 영향이 긍정적이고 그 위험이 관리 가능하다는 확신을 얻을 때에만 개발되어야 합니다. 이러한 확신은 그 시스템의 잠재적인 영향의 크기에 따라 잘 정당화되어야 합니다. OpenAI의 인공 일반 지능에 관한 최근 발표에서는 "미래의 시스템을 학습하기 전에 독립적인 검토가 필요하며, 새로운 모델을 만드는 데 사용되는 계산 능력의 성장 속도를 제한하는 것에 대해 가장 진보된 노력이 합의해야 할 수도 있다"고 명시되어 있습니다. 우리는 동의합니다. 이 시점이 지금입니다.  
>  
> 그러므로 우리는 모든 AI 연구소에게 GPT-4보다 강력한 AI 시스템의 학습을 적어도 6개월간 즉시 중단하도록 요청합니다. 이러한 중단은 공개적이고 검증 가능하며 모든 주요 참여자를 포함해야 합니다. 이러한 중단을 빠르게 시행할 수 없는 경우 정부는 모라토리엄을 시행해야 합니다.  
>  
> 이러한 일시적 중단을 통해, AI 연구소와 독립 전문가들은 외부 독립 전문가들의 엄격한 감사와 감독 하에 검증된 고급 AI 설계 및 개발을 위한 공유 안전 프로토콜을 공동으로 개발하고 구현해야 합니다. 이러한 프로토콜은 그들이 따르는 시스템이 합리적인 의심을 넘어 안전하다는 것을 보장해야 합니다. 이는 AI 개발 전반에 대한 일시 중단을 의미하지 않습니다. 대신, 불확실한 급격한 블랙박스 모델의 발전 경쟁에서 조금 물러서야 한다는 뜻입니다.  
>  
> AI 연구와 개발은 오늘날의 강력하고 최신 시스템을 보다 정확하고 안전하며 해석 가능하고 투명하며 견고하며 일치하며 신뢰할 수 있고 충성스러운 시스템으로 개선해야 합니다.  
>  
> 동시에 AI 개발자들은 정책 결정자들과 협력하여 견고한 AI 거버넌스 시스템을 급속하게 개발해야 합니다. 이에는 적어도 다음이 포함되어야 합니다. AI에 특화된 새로운 강력한 규제 당국; 고성능 AI 시스템 및 대규모 계산 능력의 감시 및 추적; 실제와 합성을 구분하고 모델 유출을 추적하는 기원성과 워터마킹 시스템; 견고한 감사 및 인증 생태계; AI로 인한 피해에 대한 책임; 기술적 AI 안전 연구를 위한 견고한 공공 자금 지원; AI가 야기할 수 있는 극적인 경제 및 정치적 혼란에 대처하기 위한 잘 자원화된 기관.  
>  
> 인류는 AI와 함께 번영하는 미래를 즐길 수 있습니다. 강력한 AI 시스템을 만들어냄으로써, 우리는 이제 모두에게 이익이 되는 시스템을 엔지니어링하고 보상을 누리며 사회가 적응할 기회를 제공할 수 있습니다. 사회는 잠재적으로 치명적인 영향을 미칠 수 있는 다른 기술들에서도 중단을 했습니다. 여기서도 그렇게 할 수 있습니다. 우리는 준비되지 않은 상태로 서둘러서는 안 됩니다. 긴 AI 여름을 즐겨봅시다.  

현재 OpenAI가 GPT-5를 개발 중에 있고, 루머에 의하면 25,000개의 고성능 GPU가 사용될만큼 엄청난 규모라고 하는데, 이 Open Letter가 GPT-5를 포함한 거대 AI 시스템 개발 전반에 어떤 영향이 줄지 궁금해진다. 

참고로, 일론 머스크는 테슬라와 OpenAI 사이에서 발생한 이해충돌 문제 (직원 빼내기 등)의 이유로 OpenAI를 떠난 상태이며, Open Letter에 서명한 것이 OpenAI에 대한 견제를 위한 것이 아닌가 하는 의문도 조금 든다. 