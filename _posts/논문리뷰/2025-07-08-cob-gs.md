---
title: "[논문리뷰] COB-GS: Clear Object Boundaries in 3DGS Segmentation Based on Boundary-Adaptive Gaussian Splitting"
last_modified_at: 2025-07-08
categories:
  - 논문리뷰
tags:
  - Gaussian Splatting
  - Novel View Synthesis
  - 3D Vision
  - CVPR
excerpt: "COB-GS 논문 리뷰 (CVPR 2025)"
use_math: true
classes: wide
---

> CVPR 2025. [[Paper](https://arxiv.org/abs/2503.19443)] [[Github](https://github.com/ZestfulJX/COB-GS)]  
> Jiaxin Zhang, Junjun Jiang, Youyu Chen, Kui Jiang, Xianming Liu  
> Harbin Institute of Technology  
> 25 Mar 2025  

<center><img src='{{"/assets/img/cob-gs/cob-gs-fig1.webp" | relative_url}}' width="63%"></center>

## Introduction
현재 3DGS segmentation을 실행하는 데는 feature 기반 방법과 마스크 기반 방법, 두 가지 주요 방법이 있다. Feature 기반 방법은 일반적으로 3D 장면 재구성과 함께 작동하여 각 Gaussian의 고유한 feature 속성을 학습시킨다. Segmentation 단계에서 3D Gaussian feature와 쿼리된 feature 간의 유사도를 계산하여 원하는 semantic을 가진 Gaussian을 선택한다. 그러나 이러한 방법은 비효율적인 학습 및 렌더링 프로세스와 고차원 feature 표현과 관련된 모호성 문제에 직면한다.

이러한 우려를 완화하기 위해 마스크 기반 후처리 방법은 [Segment Anything Model (SAM)](https://kimjy99.github.io/논문리뷰/segment-anything)의 입력 뷰의 semantic mask를 활용하여 재구성된 3DGS 장면의 각 3D Gaussian에 대한 카테고리 레이블을 학습시키고 지정된 쿼리 레이블로 이러한 Gaussian을 필터링하여 3D segmentation을 수행한다. 이러한 발전에도 불구하고 기존 방법들은 semantic 정보를 무시하고 주로 시각적 최적화에 초점을 맞추기 때문에, 장면 segmentation 중 경계 Gaussian에 대한 레이블이 흐릿해지고 흐릿한 가장자리를 가진 부정확한 segmentation 결과가 발생한다. 일부 기존 방법은 모호한 경계 Gaussian을 직접 제거하지만, 그러면 시각적 품질이 저하된다.

이러한 문제를 해결하기 위해, 본 논문에서는 semantic과 외형을 함께 최적화하여 semantic mask를 각 Gaussian에 등록하는 3DGS segmentation 방법인 **COB-GS**를 제안하였다. 기존 방법과 유사하게, segmentation을 위해 각 Gaussian에 마스크 레이블을 추가 속성으로 도입하였다. 또한, 마스크 최적화 단계에서 마스크 레이블의 gradient 통계를 활용하여 경계 Gaussian을 식별하고 분할하여 물체 경계와의 정확한 정렬을 가능하게 한다. 장면 최적화 단계에서는 시각적 품질을 유지하기 위해 정확한 경계 구조에서 장면 텍스처를 정제한다. 장면 최적화 후, 3D segmentation은 마스크 레이블 필터링에 중점을 둔다. 미세한 경계 Gaussian을 개선함으로써, 사전 학습된 모델의 부정확한 마스크에 대한 robustness를 향상시킨다. 마지막으로, [SAM2](https://kimjy99.github.io/논문리뷰/segment-anything-2) 기반의 2단계 마스크 생성 방법을 도입하여 3D 재구성 데이터셋에서 관심 영역 마스크 추출을 크게 간소화하였다.

## Method
<center><img src='{{"/assets/img/cob-gs/cob-gs-fig2.webp" | relative_url}}' width="100%"></center>

### 1. Boundary-Adaptive Gaussian Splitting
효율성을 위해 각 Gaussian에 대해 연속적인 마스크 레이블 $m_i \in (0, 1)$을 도입한다. $m_i$가 1에 가까우면 $i$번째 Gaussian이 3D segmentation에 필요함을 나타내고, $m_i$가 0에 배경에 속함을 나타낸다. 색상 렌더링 과정과 유사하게, 3D Gaussian의 마스크 레이블은 알파 블렌딩을 통해 결합되어 2D 픽셀 공간에서 마스크 $$M_\textrm{render}$$를 생성한다.

$$
\begin{equation}
M_\textrm{render} = \sum_{i=1}^N m_i \alpha_i \prod_{j=1}^{i-1} (1 - \alpha_j) = \sum_{i=1}^N m_i \alpha_i T_i
\end{equation}
$$

[SA3D](https://kimjy99.github.io/논문리뷰/sa3d)에서 영감을 받아, 마스크 레이블 학습 과정에 유사한 loss function을 사용한다.

$$
\begin{equation}
\mathcal{L}_\textrm{mask} = -\sum_{M_{jk}^v} M_{jk}^v \cdot M_\textrm{render}^v + \sum_{M_{jk}^v} (1 - M_{jk}^v) \cdot M_\textrm{render}^v
\end{equation}
$$

($$M_{jk}^v \in \{0, 1\}$$은 뷰 $v$에 대한 픽셀 $(j, k)$의 GT 마스크)

##### Boundary-Adaptive Gaussian Splitting
원래 3DGS는 RGB loss에 의존했는데, 3D Gaussian을 형성하는 데 사용되는 물체 수준의 semantic 정보가 부족했다. 결과적으로, 고정된 형상과 텍스처를 분할하면 의미적으로 모호한 경계 Gaussian이 생성된다. 따라서 명확한 물체 경계를 얻으려면 이러한 모호한 Gaussian을 찾고 분할하는 것이 중요하다.

이 문제를 해결하기 위해, 모호한 Gaussian 식별을 위해 마스크 최적화 단계에서 마스크 레이블의 기울기를 사용한다. 구체적으로, 시점 $v$에 있는 픽셀 위치 $(j, k)$에 대해, $$\mathcal{L}_\textrm{mask}^{vjk}$$을 $m_i$에 대하여 미분하면 다음과 같다.

$$
\begin{equation}
\frac{\textrm{d} \mathcal{L}_\textrm{mask}^{vjk}}{\textrm{d} m_i} = \begin{cases} - \alpha_i T_i, & \; \textrm{if} \; M_{jk}^v = 1 \\ \alpha_i T_i, & \; \textrm{if} \; M_{jk}^v = 0 \end{cases}
\end{equation}
$$

$m_i$에 대한 $$\mathcal{L}_\textrm{mask}^v$$의 기울기 계산은 여러 픽셀의 영향을 받으며, 이는 다음과 같다.

$$
\begin{equation}
\frac{\textrm{d} \mathcal{L}_\textrm{mask}^v}{\textrm{d} m_i} = \sum_{j=1}^{N_{v,i}^{+}} (- \alpha_j T_j) + \sum_{j=1}^{N_{v,i}^{-}} (\alpha_j T_j)
\end{equation}
$$

($$N_{v,i}^{+}$$와 $$N_{v,i}^{-}$$는 $i$번째 Gaussian에 영향을 받는 픽셀 중 GT 마스크가 각각 1과 0인 신호의 개수)

따라서 시점 $v$에서의 누적 기울기는 모호한 경계 Gaussian을 구분하는 데 효과적이지 않지만, gradient의 부호는 마스크 레이블의 카테고리를 반영한다. 따라서, backpropagation하는 동안 각 Gaussian에 대해 새로운 변수 $$\textrm{mask_sig}$$를 도입하여, 특정 시점 $v$에서의 마스크 레이블에 대한 supervision 신호의 일관성 강도를 상대적 거리의 절대값을 사용하여 계산할 수 있다.

$$
\begin{equation}
\textrm{mask_sig}_{v,i} = \left\vert \frac{N_{v,i}^{+} - N_{v,i}^{-}}{N_{v,i}^{+} + N_{v,i}^{-} + \epsilon} \right\vert
\end{equation}
$$

($\epsilon$은 작은 상수)

$$\textrm{mask_sig}$$가 0에 가까울수록 해당 Gaussian이 의미적으로 모호함을 뜻한다. 마스크 레이블 최적화 과정에서 threshold 미만의 $$\textrm{mask_sig}$$를 갖는 Gaussian은 의미적으로 모호한 경계 Gaussian 집합 $$\{G_i\}_B$$로 식별된다.

$$
\begin{equation}
\{G_i\}_B = \{G_i \; \vert \; i \in \mathcal{I} \; \wedge \; \left( \frac{1}{V} \sum_{v=1}^V \textrm{mask_sig}_{v,i} < \delta \right)\}
\end{equation}
$$

($\delta$는 threshold, $$\mathcal{I} = \{1, \ldots, \vert \{ G_i \} \vert \}$$)

Splitting 과정에서 원래의 3D Gaussian Splatting과 동일하다. 먼저, $$\{G_i\}_B$$에서 작은 scale의 Gaussian을 제외한다. 나머지 큰 Gaussian은 각각 두 개의 작은 Gaussian으로 대체하여 원래 Gaussian보다 크기를 줄인다. 그런 다음, 원래 Gaussian을 확률 밀도 함수(PDF)로 사용하여 초기 위치를 샘플링한다.

##### Boundary-Guided Scene Texture Restoration
<center><img src='{{"/assets/img/cob-gs/cob-gs-fig3.webp" | relative_url}}' width="55%"></center>
<br>
기존의 장면 segmentation 방법은 경계가 모호한 Gaussian을 직접 제거하거나 전경 Gaussian에만 집중하였다. 이러한 coarse한 방법은 시각적 품질을 저하시킬 수 있으며, 물체 수준의 semantic 조건이 장면 텍스처 학습에 충분히 활용되지 않는다.

이 문제를 해결하기 위해, 마스크 레이블과 Gaussian의 형상 및 텍스처를 번갈아 학습시킨다. 물체 수준의 semantic 정보를 통합하면 경계 Gaussian의 양을 효과적으로 제한하고, 정확한 경계 구조에 대한 텍스처 최적화는 새로운 뷰의 시각적 품질을 향상시킨다.

구체적으로, Gaussian의 형상 정보와 텍스처 정보를 학습시키기 위한 loss function은 원래 Gaussian 최적화 프로세스와 일치한다.

$$
\begin{equation}
\mathcal{L}_\textrm{rgb} = (1 - \lambda) \mathcal{L}_1 + \lambda \mathcal{L}_\textrm{D-SSIM}
\end{equation}
$$

먼저 Gaussian의 형상과 텍스처를 고정하고 $$\mathcal{L}_\textrm{mask}$$를 최소화하여 마스크 레이블을 최적화한다. 특정 개수의 학습 뷰에서 모호한 경계 Gaussian을 찾아 분할한다. 분할 단계에서 장면의 형상과 텍스처가 손상되어 시각적 품질이 크게 저하된다. 따라서 정확한 경계 구조에서 장면의 형상 및 텍스처 디테일을 개선하기 위해, 마스크 레이블을 고정하고 $$\mathcal{L}_\textrm{rgb}$$를 최적화한다. 이 두 단계는 반복적으로 번갈아 수행되며, 이를 통해 정확한 물체 경계를 보장하고 시각적 품질을 유지한다.

##### Robustness Against Erroneous Masks
<center><img src='{{"/assets/img/cob-gs/cob-gs-fig4.webp" | relative_url}}' width="100%"></center>
<br>
마스크와 텍스처를 번갈아 최적화함으로써 모호한 Gaussian의 수는 점진적으로 감소해야 한다. Segmentation 단계에서는 마스크 레이블을 기반으로 장면을 분할한다. 그러나 큰 모호한 Gaussian의 수는 감소하지만, 작은 모호한 Gaussian은 여전히 ​​많이 남아 있다.

실제로, 2D 비전 모델에서 예측된 바이너리 마스크 $$\​\{M^v\}$$는 불연속성을 나타내며, 종종 여러 뷰에서 물체 경계 예측의 부정확성과 불일치로 이어진다. 이러한 한계로 인해 최적화 과정에서 경계 Gaussian의 마스크 레이블이 수렴하지 못할 수 있다. 

부정확한 마스크로 인해 발생하는 경계 흐림 현상을 복합적으로 처리하는 기존 방법과 달리, 본 논문에서는 공동 최적화의 최종 단계를 활용하여 부정확한 마스크에 대한 robustness를 향상시킨다. 구체적으로, 더 낮은 $$\textrm{mask_sig}_{v,i}$$와 scale $s$를 기반으로 semantic이 모호한 작은 경계 Gaussian을 식별하고, 해당 Gaussian들을 제거한다. 

##### Multi-Object 3D Segmentation
실제 3DGS 장면에는 여러 물체가 포함된다. Feature 기반 방법은 쿼리를 위해 각 Gaussian에 feature를 할당하기 위해 시간이 많이 소요되는 전체 장면 학습 과정을 필요로 한다. 이러한 방법은 정확한 물체 경계를 위해 마스크를 사용하여 장면을 정규화하는데, 이는 segmentation의 세분성을 제한한다. 마찬가지로, 전체 장면 레이블을 학습하는 마스크 기반 방법도 비슷한 어려움에 직면한다.

본 논문에서는 여러 물체에 대한 segmentation을 순차적인 단일 물체에 대한 segmentation으로 분해하였다. 각 Gaussian에 단일 정수 값을 할당하고 실시간 렌더링을 활용하여 개별 segmentation을 가속화하고 세분성 문제를 해결하였다. 구체적으로, $K$개의 물체에 대해 마스크 집합 $$\{M^v\}_k$$를 정의한다 ($$k \in \{1, \ldots, K\}$$). $k$번째 물체를 최적화할 때는 텍스처와 공동 최적화를 통해 명확한 물체 경계를 가진 새로운 3DGS $$\{G_i\}_k$$를 얻는 Gaussian splitting을 수행한다. 이후 물체에 대한 최적화 프로세스는 업데이트된 3DGS $$\{G_i\}_k$$에서 수행되며, 모든 $K$개의 물체가 최적화될 때까지 반복된다. 

### 2. Two-Stage Mask Generation
마스크 기반 3DGS 분할은 입력 이미지를 기반으로 대상 물체에 대한 마스크를 생성하는 과정을 포함한다. 본 논문에서 학습 데이터는 $V$개의 입력 이미지 $$\{I^v\}$$와 이에 대응하는 2D 바이너리 마스크 ​​$$\{M^v\}$$로 구성된다. [SAM2](https://kimjy99.github.io/논문리뷰/segment-anything-2)와 같은 foundation model의 개발로 이미지 시퀀스 전반에 걸친 마스크 예측이 가능해졌으며, 프레임 간 일관성이 크게 향상되었다. 그러나 SAM2는 긴 시퀀스에서 물체 연속성 문제에 직면하여 시각 정보의 불연속성으로 인해 심하게 가려진 물체를 추론하지 못할 가능성이 있다.

이러한 한계를 해결하기 위해, 저자들은 텍스트 프롬프트를 활용하는 2단계 마스크 생성 접근법을 제안하였다. Coarse 단계에서는 Grounding-DINO를 사용하여 텍스트 신뢰도가 낮은 프레임에서 박스 프롬프트를 추출하고, 이를 전체 시퀀스에 적용하여 초기 마스크 예측을 수행한다. Fine-grained 단계에서는 텍스트 신뢰도가 높은 Grounding-DINO를 사용하여 coarse 단계에서 마스크 예측이 중단된 부분 시퀀스에 대한 박스 프롬프트를 추출한다. 이렇게 추출된 프롬프트는 부분 시퀀스에 대한 최종 마스크 예측을 생성한다. 

## Experiments
### 1. Quantitative Results
다음은 NVOS 데이터셋에서의 (왼쪽) segmentation 결과와 (오른쪽) 시각적 품질을 비교한 표이다. 

<div style="display: flex; align-items: start; justify-content: center">
  <img src='{{"/assets/img/cob-gs/cob-gs-table1.webp" | relative_url}}' width="46%">
  <div style="flex-grow: 0; width: 2%;"></div>
  <img src='{{"/assets/img/cob-gs/cob-gs-table2.webp" | relative_url}}' width="46%">
</div>

### 2. Qualitative Results
다음은 단일 물체에 대한 segmentation 결과를 비교한 것이다. 

<center><img src='{{"/assets/img/cob-gs/cob-gs-fig5.webp" | relative_url}}' width="100%"></center>
<br>
다음은 여러 물체에 대한 segmentation 결과를 비교한 것이다. 

<center><img src='{{"/assets/img/cob-gs/cob-gs-fig6.webp" | relative_url}}' width="80%"></center>

### 3. Ablation Study
다음은 semantic과 텍스처의 공동 최적화에 대한 ablation 결과이다. (Vanilla는 원래 장면, M.O와는 마스크가 최적화된 장면, T.O는 텍스처가 최적화된 장면)

<center><img src='{{"/assets/img/cob-gs/cob-gs-fig7.webp" | relative_url}}' width="90%"></center>
<span style="display: block; margin: 1px 0;"></span>
<center><img src='{{"/assets/img/cob-gs/cob-gs-table3.webp" | relative_url}}' width="58%"></center>
<br>
다음은 각 방법에 대한 ablation 결과이다. (BAGS는 boundary-adaptive Gaussian splitting, BGTR은 boundary-guided texture restoration, RAEM은 robustness against erroneous masks)

<center><img src='{{"/assets/img/cob-gs/cob-gs-table4.webp" | relative_url}}' width="41%"></center>
<br>
다음은 threshold $\delta$에 대한 ablation 결과이다. 

<center><img src='{{"/assets/img/cob-gs/cob-gs-fig8.webp" | relative_url}}' width="65%"></center>