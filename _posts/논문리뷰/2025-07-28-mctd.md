---
title: "[논문리뷰] Monte Carlo Tree Diffusion for System 2 Planning"
last_modified_at: 2025-07-28
categories:
  - 논문리뷰
tags:
  - Diffusion
  - Reinforcement Learning
  - ICML
excerpt: "MCTD 논문 리뷰 (ICML 2025 Spotlight)"
use_math: true
classes: wide
---

> ICML 2025 (Spotlight). [[Paper](https://arxiv.org/abs/2502.07202)]  
> Jaesik Yoon, Hyeonseo Cho, Doojin Baek, Yoshua Bengio, Sungjin Ahn  
> KAIST | SAP | Mila | New York University  
> 11 Feb 2025  

## Introduction
Diffusion model은 최근 대규모 오프라인 데이터를 사용하여 궤적 분포를 모델링하여 복잡한 궤적을 생성할 수 있는 강력한 계획 접근법으로 부상했습니다. 기존의 자기회귀 계획 방법과 달리, Diffuser와 같은 diffusion 기반 planning 도구는 일련의 denoising step을 거쳐 전체 궤적을 전체적으로 생성하므로 순방향 동역학 모델이 필요하지 않습니다. 이 접근법은 장기 종속성 모델링의 취약성 및 오류 누적과 같은 순방향 모델의 주요 한계를 효과적으로 해결하여, 특히 장기 계획 기간이나 희소한 보상이 있는 계획 작업에 적합합니다.

이러한 장점에도 불구하고, diffusion 기반 플래너가 inference-time scalability를 통해 어떻게 planning 정확도를 효과적으로 향상시킬 수 있는지는 여전히 불확실합니다. 한 가지 가능한 접근 방식은 노이즈 제거 단계 수를 늘리거나, 또는 추가 샘플을 추출하는 것입니다. 그러나 denoising step 증가로 인한 성능 향상은 빠르게 정체되고, 여러 샘플을 사용하는 독립적인 무작위 검색은 다른 샘플의 정보를 활용하지 못하기 때문에 매우 비효율적인 것으로 알려져 있습니다. 더욱이, 이 프레임워크 내에서 탐색-활용 트레이드오프를 효과적으로 관리하는 방법 또한 불확실합니다.

이와 대조적으로, 널리 채택된 planning 방법인 Monte Carlo Tree Search (MCTS)는 강력한 inference-time scalability를 보여줍니다. MCTS는 반복적인 시뮬레이션을 활용하여 탐색적 피드백을 기반으로 결정을 개선하고 적응하며, 더 많은 계산이 할당됨에 따라 계획 정확도를 향상시키는 데 매우 효과적입니다. 이러한 기능 덕분에 MCTS는 수학적 문제 해결 및 프로그램 합성과 같은 많은 시스템 2 추론 작업에서 초석으로 자리 잡았습니다. 그러나 diffusion 기반 계획 도구와 달리, 기존 MCTS는 트리 rollout을 위해 순방향 모델에 의존하며, 전역 일관성 손실을 포함한 한계를 그대로 이어받습니다. 이산적인 행동 공간으로 제한될 뿐만 아니라, 결과 탐색 트리는 깊이와 너비 모두에서 지나치게 커질 수 있습니다. 이는 특히 긴 시야와 넓은 행동 공간이 포함된 시나리오에서 상당한 계산 요구 사항을 초래합니다.

이는 중요한 질문을 제기합니다. 디퓨저와 MCTS의 강점을 어떻게 결합하여 그 한계를 극복하고 diffusion 기반 계획의 추론 시간 확장성을 향상시킬 수 있을까요? 이 문제를 해결하기 위해, 우리는 더욱 효율적이고 확장 가능한 planning을 위해 diffusion 기반 궤적 생성과 MCTS의 반복적 탐색 기능을 통합하는 프레임워크인 **Monte Carlo Tree Diffusion (MCTD)**을 제안합니다.

MCTD는 세 가지 핵심 혁신을 기반으로 합니다. 첫째, denoising을 트리 기반 rollout 프로세스로 재구성하여 궤적 일관성을 유지하면서 반자기회귀 인과 관계 계획을 가능하게 합니다. 둘째, 탐색과 활용의 균형을 동적으로 맞추기 위해 메타 액션으로 안내 수준을 도입하여 diffusion 프레임워크 내에서 적응적이고 확장 가능한 궤적 개선을 보장합니다. 셋째, 빠른 점피 denoising을 시뮬레이션 메커니즘으로 사용하여 비용이 많이 드는 순방향 모델 rollout 없이 궤적 품질을 효율적으로 추정합니다. 이러한 혁신을 통해 diffusion 계획 내에서 MCTS(선택, 확장, 시뮬레이션, 역전파)의 4단계를 구현하여 구조적 탐색과 생성 모델링을 효과적으로 연결합니다. 실험 결과, MCTD는 장기 작업에서 기존 접근 방식보다 우수한 성능을 보이며, 탁월한 확장성과 솔루션 품질을 달성합니다.

## Preliminaries
[Diffuser](https://kimjy99.github.io/논문리뷰/diffuser)는 전체 궤적을 다음과 같은 행렬로 처리하여 long-horizon decision-making을 처리한다. 

$$
\begin{equation}
\textbf{x} = \begin{bmatrix} s_0 & s_1 & \ldots & s_T \\ a_0 & a_1 & \ldots & a_T \end{bmatrix}
\end{equation}
$$

($s_t$와 $a_t$는 각각 시간 $t$에서의 state와 action)

그런 다음, diffusion process를 학습시켜 $\textbf{x}$의 샘플에서 noise 반복적으로 제거하여 궁극적으로 일관된 궤적을 생성한다. 실제로 이는 궤적 공간에 대해 denoiser $$p_\theta (\textbf{x})$$를 학습시켜 forward process를 역으로 수행하는 것과 같다. $$p_\theta$$ 자체는 reward나 기타 task 목표를 인코딩하지 않으므로, Diffuser는 선택적으로 휴리스틱 또는 학습된 guidance function $$J_\phi (\textbf{x})$$를 통합한다. 이 함수는 부분적으로 denoise된 궤적의 return이나 value를 예측하여 샘플링 분포에 편향을 발생시킨다.

$$
\begin{equation}
\tilde{p}_\theta (\textbf{x}) \propto p_\theta (\textbf{x}) \exp (J_\phi (\textbf{x}))
\end{equation}
$$

따라서 각 denoising step에서 $$J_\phi$$의 gradient 정보는 모델을 오프라인 데이터에서 학습한 것처럼 실행 가능하고 return과 관련하여 유망해 보이는 궤적으로 밀어붙인다. 이는 이미지 diffuser의 [classifier guidance](https://kimjy99.github.io/논문리뷰/dmbg)와 유사한 방식이다.

[Diffusion Forcing](https://kimjy99.github.io/논문리뷰/diffusion-forcing)는 $\textbf{x}$의 tokenization을 허용함으로써 Diffuser를 확장하였다. 이 tokenization을 통해 각 토큰의 noise level을 다르게 하여 불확실성이 높은 구간의 부분적인 denoising이 가능하며, 전체 궤적에 걸쳐 noise가 완전히 없도록 전환할 필요가 없다. 이러한 토큰 수준 제어는 특히 long-horizon planning 문제와 같이 인과적 일관성이 요구되는 영역에서 유용하다.

## Monte Carlo Tree Diffusion
<center><img src='{{"/assets/img/mctd/mctd-fig1.webp" | relative_url}}' width="100%"></center>

### 1. Denoising as Tree-Rollout
기존 MCTS는 개별 상태를 기반으로 작동하기 때문에 탐색 트리가 깊어지고 확장성 측면에서 상당한 어려움을 겪습니다. 트리의 각 노드가 단일 상태를 나타내기 때문에 트리의 깊이는 계획 범위에 따라 선형적으로 증가하여 탐색 공간이 기하급수적으로 증가합니다. 또한, diffusion 기반 계획자가 본질적으로 제공하는 전체 궤적에 대한 전체적인 관점이 부족합니다. 반면, Diffuser는 활용과 탐색의 균형을 효과적으로 유지하는 중간 의사결정 지점 탐색에 필요한 트리 구조를 제공하지 않습니다.

이 문제를 해결하기 위해, 먼저 반자기회귀적 잡음 제거 프로세스를 활용하여 트리-rollout으로서의 잡음 제거 프로세스를 도입합니다. 구체적으로, 전체 궤적 x = (x1, x2, ..., xN)을 S개의 하위 계획 x = (x1, x2, ..., xS)으로 분할하여 ∩sxs = ∅가 되도록 합니다. 모든 하위 계획이 동일한 전역 잡음 제거 스케줄을 공유하는 표준 디퓨저와 달리, 본 접근법은 각 하위 계획에 독립적인 잡음 제거 스케줄을 할당할 수 있도록 합니다. 이전 하위 계획에는 더 빠른 잡음 제거를 적용하고 이후 하위 계획에는 더 느린 잡음 제거를 적용함으로써, 프로세스는 사실상 인과적이고 반자기회귀적이 됩니다. 이를 통해 잡음 제거 프로세스는 이미 결정된 과거를 기반으로 미래를 결정할 수 있습니다. 결과적으로, 디퓨저의 전역적으로 일관되고 전체론적인 생성 이점을 유지하면서 잡음 제거 프로세스는 다음과 같이 근사합니다.

$$
\begin{equation}
p(\textbf{x}) \approx \prod_{s=1}^S p (\textbf{x}_s \vert \textbf{x}_{1:s-1})
\end{equation}
$$

주목할 점은 이 공식이 자기회귀적인 것처럼 보이지만 여전히 하위 계획 전체에서 노이즈 수준을 제어하여 단일 denoising process로 실행된다는 것입니다.

MCTD에서는 시간적으로 확장된 상태를 나타내는 각 하위 계획 xs가 개별 상태 xn을 노드로 사용하는 대신 탐색 트리의 노드로 처리됩니다. 이를 통해 트리가 더 높은 수준의 추상화에서 작동하여 효율성과 확장성을 향상시킵니다. 전체 계획 x의 노이즈 제거는 Diffuser의 단일 노이즈 제거 프로세스를 통해 이러한 노드 시퀀스를 rollout하는 것으로 볼 수 있습니다. S ≪ N이므로 트리 깊이는 MCTS보다 훨씬 작아집니다. 예를 들어, 우리의 계획 실험 중 하나에서는 S = 5, N = 500을 사용합니다.

### 2. Guidance Levels as Meta-Actions
MCTS에서 트리를 구성하고 탐색하는 것은 넓은 행동 공간에서는 계산적으로 비용이 많이 들고, 연속 행동 공간에서는 근본적으로 비실용적입니다. 이 문제를 해결하기 위해 MCTD에서는 메타 행동의 관점에서 탐색-활용 트레이드오프를 재정의하는 새로운 접근법을 도입합니다. 메타 행동은 탐색-활용을 제어할 수 있는 모든 이산적인 결정일 수 있지만, 본 연구에서는 노이즈 제거 과정에서 적용되는 지침 수준으로 메타 행동을 구현하는 것을 제안합니다.

단순화를 위해 GUIDE와 NO GUIDE라는 두 가지 안내 수준을 고려해 보겠습니다. MCTD에서, 사전 분포 p(x)에서 샘플링하는 것, 즉 표준 diffusion 샘플러를 사용하는 것은 어떤 목표도 달성하려고 시도하지 않고 오프라인 데이터에 포함된 사전 행동을 모방하기 때문에 탐색적 행동을 나타냅니다. 따라서 이를 NO GUIDE 메타-행동에 대응시킵니다. 반대로, 목표 지향 분포 pg(x)에서 샘플링하는 것, 예를 들어 분류기 유도 diffusion을 사용하는 것은 착취적 행동을 나타내므로 메타-행동인 GUIDE가 할당됩니다. 이는 보상 함수 rg(x)로 정의된 특정 목표를 달성하도록 샘플링 프로세스를 조정합니다.

다음으로, 메타-작업의 개념을 Eqn. (2)에 기술된 트리 rollout 노이즈 제거 프로세스와 통합합니다. 이를 달성하기 위해, 우리는 각 해당 하위 계획 xs에 가이드 메타-작업 gs ∈ {GUIDE, NO GUIDE}를 할당하는 가이드 스케줄 g = (g1, . . . , gS)를 도입합니다. 가이드를 선택하지 않으면 하위 계획은 탐색적 트리 rollout 사전 p(xs|x1:s−1)에서 샘플링되고, 가이드가 있는 하위 계획은 GUIDE 메타-작업이 선택된 경우 pg(xs|x1:s−1)에서 샘플링됩니다. 이를 통해 표준 디퓨저가 전체 궤적과 전체 노이즈 제거 프로세스에 걸쳐 가이드를 할당하는 것과 달리 각 하위 계획에 가이드 수준을 독립적으로 할당할 수 있습니다.

안내 일정 g를 동적으로 조정함으로써 단일 노이즈 제거 프로세스 내 하위 계획 수준에서 탐사-활용 균형을 이룰 수 있습니다. 확장된 트리-rollout 노이즈 제거 프로세스는 다음과 같은 효과를 냅니다.

$$
\begin{equation}
p (\textbf{x} \vert \textbf{g}) \approx \prod_{s=1}^S p (\textbf{x}_s \vert \textbf{x}_{1:s-1}, g_s)
\end{equation}
$$

결과적으로 이 접근 방식은 복잡하거나 연속적인 작업 공간에서도 효율적이고 확장 가능한 계획을 가능하게 합니다.

### 3. Jumpy Denoising as Fast Simulation
MCTS에서 계획 평가가 가능한 리프 노드에서 멀리 떨어진 노드를 평가하는 것은 매우 중요한 요구 사항입니다. 이는 일반적으로 두 가지 방법 중 하나로 해결됩니다. 고속 전진 동역학 모델을 사용하여 리프 노드까지의 궤적을 rollout하는 방법(계산 비용이 높음)과 부트스트래핑을 통해 노드 값을 근사하는 방법(더 빠르지만 정확도는 떨어짐)이 있습니다. 그러나 이러한 시뮬레이션 전략을 디퓨저 프레임워크에 효과적으로 통합하는 방법은 여전히 미해결 과제입니다.

MCTD에서는 [DDIM](https://kimjy99.github.io/논문리뷰/ddim) 기반의 빠른 점피 노이즈 제거 프로세스를 사용하여 이 시뮬레이션 기능을 구현합니다. 구체적으로, 트리 rollout 노이즈 제거 프로세스가 s번째 하위 계획까지 진행되면 나머지 단계의 노이즈를 C번째 단계까지 빠르게 제거합니다.

$$
\begin{equation}
\tilde{\textbf{x}}_{s+1:S} \sim p (\textbf{x}_{s+1:S} \vert \textbf{x}_{1:s}, \textbf{g})
\end{equation}
$$

이렇게 하면 전체 궤적 x˜ = (x1:s, x˜s+1:S)가 생성되고, 이는 보상 함수 r(x˜)를 사용하여 계산됩니다. 이 빠른 잡음 제거 과정은 더 큰 근사 오차를 유발할 수 있지만, 계산 효율이 매우 높아 MCTD의 시뮬레이션 단계에 적합합니다.

### 4. The Four Steps of an MCTD Round
위 설명을 바탕으로, MCTS의 네 가지 기존 단계(선택, 확장, 시뮬레이션, 역전파)가 MCTD에 어떻게 적용되고 구현되는지 자세히 설명합니다. 이 과정은 그림 1에 나와 있습니다.

#### Selection
MCTD에서 선택 과정은 루트 노드에서 리프 노드 또는 부분적으로 확장된 노드까지 트리를 순회하는 과정을 포함합니다. 각 단계에서 상위 신뢰 한계(UCB)와 같은 선택 기준에 따라 자식 노드가 선택됩니다. 중요한 점은 이 단계에서는 계산량이 많은 노이즈 제거가 필요하지 않고, 기존 트리 구조를 순회한다는 것입니다. 기존 MCTS와 달리, MCTD 노드는 시간적으로 확장된 상태에 대응하여 고수준 추론을 가능하게 하고 트리 깊이를 줄여 확장성을 향상시킵니다. 안내 일정 g는 이 단계에서 UCB에 의해 동적으로 조정되어 탐색(GUIDE 없음)과 활용(GUIDE)의 균형을 맞춥니다.

#### Expansion
리프 노드 또는 부분적으로 확장된 노드가 선택되면 확장 단계에서는 현재 부분적으로 denoise된 궤적을 확장하여 새로운 자식 노드를 생성합니다. 각 자식 노드는 diffusion model을 사용하여 생성된 새로운 하위 계획에 해당합니다. 메타 액션 gs에 따라 하위 계획은 탐색적 사전 분포 p(xs|x1:s−1) 또는 목표 탐색 분포 pg(xs|x1:s−1)에서 샘플링됩니다. 메타 액션은 확장에 사용되는 동작을 제어하며, 새로 생성된 노드는 현재 궤적의 확장으로 트리에 추가됩니다. 중요한 점은 안내 수준이 이진 선택으로 제한되지 않는다는 것입니다. 예를 들어, 메타 액션을 {ZERO, LOW, MEDIUM, HIGH}와 같은 여러 안내 수준으로 일반화하여 확장 과정에서 탐색과 활용 간의 균형을 더욱 세밀하게 제어할 수 있습니다.

#### Simulation
MCTD에서의 시뮬레이션은 빠른 jumpy denoising을 통해 구현됩니다. 노드가 확장되면, 빠른 denoising을 사용하여 나머지 궤적을 빠르게 완료합니다. 그 결과 생성된 계획 x는 계획 평가기 r(x˜)에 제공됩니다. 이 접근법은 계획의 품질에 대한 충분한 추정치를 제공하는 동시에 계산 효율성을 유지합니다.

#### Backpropagation
시뮬레이션 단계 후, 전체 계획을 평가하여 얻은 보상은 트리를 통해 역전파되어 루트 경로에 있는 모든 부모 노드의 가치 추정치를 업데이트합니다. MCTD에서 이 역전파 과정은 메타 액션 기반 안내 일정도 업데이트하여 트리가 향후 반복 작업을 위해 탐색-활용 균형을 동적으로 조정할 수 있도록 합니다. 이를 통해 보상으로 표시되는 유망한 경로의 우선순위를 정하는 동시에, 조기 수렴을 방지하기 위한 충분한 탐색이 유지됩니다.

## Experiments
### 1. Maze Navigation with Point-Mass and Ant Robots
다음은 

<center><img src='{{"/assets/img/mctd/mctd-table1.webp" | relative_url}}' width="50%"></center>
<br>
다음은 

<center><img src='{{"/assets/img/mctd/mctd-fig3.webp" | relative_url}}' width="50%"></center>
<br>
다음은 

<center><img src='{{"/assets/img/mctd/mctd-fig2.webp" | relative_url}}' width="50%"></center>

### 2. Robot Arm Cube Manipulation
OGBench의 multi-cube manipulation task의 경우 로봇 팔은 1~4개의 큐브를 특정 테이블 위치로 이동해야 한다. 큐브 수를 늘리면 planning horizon과 복잡성이 모두 커진다. 다음은 1~4개의 큐브에 대한 성공률을 비교한 결과이다.

<center><img src='{{"/assets/img/mctd/mctd-table2.webp" | relative_url}}' width="85%"></center>
<br>
MCTD는 적당한 성능 향상을 보이지만, 여러 물체가 관련될 경우 전체적인 계획 얽힘 현상이 발생한다. 이를 해결하기 위해 MCTD-Replanning은 주기적으로 다시 planning하여 각 큐브의 이동을 효과적으로 분리한다.

<center><img src='{{"/assets/img/mctd/mctd-fig4.webp" | relative_url}}' width="65%"></center>

### 3. Visual Pointmaze
다음은 이미지 기반 planning을 평가하기 위한 visual pointmaze에서의 평가 결과이다.

<center><img src='{{"/assets/img/mctd/mctd-fig5.webp" | relative_url}}' width="75%"></center>
<span style="display: block; margin: 1px 0;"></span>
<center><img src='{{"/assets/img/mctd/mctd-table3.webp" | relative_url}}' width="85%"></center>

### 4. Inference-Time Scalability & Time Complexity
다음은 

<center><img src='{{"/assets/img/mctd/mctd-fig6.webp" | relative_url}}' width="65%"></center>
<br>

### 5. Ablation Studies
다음은 통계적 tree search가 exploration과 exploitation의 균형을 이루는 데 얼마나 효과적인지 평가하기 위해 greedy tree search를 평가한 결과이다. (PointMaze)

<center><img src='{{"/assets/img/mctd/mctd-table4.webp" | relative_url}}' width="38%"></center>
<br>
다음은 

<center><img src='{{"/assets/img/mctd/mctd-table5.webp" | relative_url}}' width="45%"></center>
<br>
다음은 

<center><img src='{{"/assets/img/mctd/mctd-table6.webp" | relative_url}}' width="85%"></center>
<br>
다음은 

<center><img src='{{"/assets/img/mctd/mctd-table7.webp" | relative_url}}' width="85%"></center>

## Limitations


