---
title: "[논문리뷰] FLoD: Integrating Flexible Level of Detail into 3D Gaussian Splatting for Customizable Rendering"
last_modified_at: 2024-09-13
categories:
  - 논문리뷰
tags:
  - Gaussian Splatting
  - 3D Vision
  - Novel View Synthesis
  - AI
excerpt: "FLoD 논문 리뷰"
use_math: true
classes: wide
---

> arXiv 2024. [[Paper](https://arxiv.org/abs/2408.12894)] [[Page](https://3dgs-flod.github.io/flod.github.io/)]  
> Yunji Seo, Young Sun Choi, Hyun Seung Son, Youngjung Uh  
> Yonsei University  
> 23 Aug 2024  

<center><img src='{{"/assets/img/flod/flod-fig1.PNG" | relative_url}}' width="65%"></center>

## Introduction
[3D Gaussian Splatting (3DGS)](https://kimjy99.github.io/논문리뷰/3d-gaussian-splatting)은 매우 빠른 렌더링 속도에서 사실적인 품질을 보여주었다. 상당한 발전에도 불구하고 3DGS는 상당한 메모리가 필요하다. 장면에서 복잡한 물체의 수가 증가함에 따라 정확한 모델링을 위해 더 많은 Gaussian이 필요하여 메모리 사용량이 증가하고 프레임 속도가 낮아진다. 메모리 필요량의 증가로 인해 장면을 렌더링하기 위해 대용량 GPU 메모리가 있는 하이엔드 장치가 필요하여 메모리 용량이 다양한 장치에서 렌더링할 수 있는 유연성이 제한된다.

저자들은 렌더링에서 더 큰 유연성이 필요하다는 필요성에 따라 3DGS 프레임워크에 LoD (Level of Detail) 개념을 통합했다. 이를 통해 디테일 수준을 조정하여 다양한 하드웨어 파워를 갖춘 다양한 시스템에서 애플리케이션이 효과적으로 작동할 수 있다. 3DGS에 LoD를 통합하는 최근 연구들은 하이엔드 GPU에서 실시간 렌더링을 가능하게 하였지만 저가형 장치에 대한 유연성이 부족하다. 따라서 LoD를 3DGS에 통합하여 하이엔드 서버에서 노트북에 이르기까지 더 광범위한 하드웨어를 수용할 수 있는 보다 유연한 렌더링 옵션을 제공하는 것이 본 논문의 목표이다. 

본 논문에서는 3DGS 내에서 사용 가능한 메모리 용량을 충족하는 레벨을 선택하면서도 전체 장면 콘텐츠를 보존할 수 있는 유연성을 제공하는 방법인 **Flexible Level of Detail (FLoD)**을 소개한다. 각 Gaussian 레벨에 scale 범위를 설정하여 각 레벨에 맞는 디테일을 갖도록 설계한다. 또한 레벨 전체에서 일관된 3D 구조를 유지하고 모든 레벨에서 향상된 렌더링 품질을 달성하기 위해 레벨별로 학습을 진행한다. 여러 레벨의 표현을 통해 이미지를 여러 디테일로 렌더링할 수 있으며, 이를 선택적 렌더링이라고 한다. 

선택적 렌더링을 통해 이미지 품질 손실을 최소화하면서 더 빠르고 메모리 효율적인 렌더링이 가능하다. 결과적으로 FLoD는 사용자에게 다양한 메모리 용량의 장치에서 작동하는 커스터마이징 가능한 렌더링 옵션을 제공한다. 또한 FLoD는 3DGS 기반 모델에 쉽게 통합될 수 있으며 기본 모델과 비교하여 추가 계산 비용 없이 렌더링 품질을 향상시킨다. 

## Method
<center><img src='{{"/assets/img/flod/flod-fig2.PNG" | relative_url}}' width="100%"></center>
<br>
본 논문의 방법은 레벨 1에서 $$L_\textrm{max}$$까지 다양한 크기의 3D Gaussian을 사용하여 장면을 $$L_\textrm{max}$$개의 레벨로 구성된 3D Gaussian 표현으로 재구성한다. 레벨별 학습을 통해 각 레벨은 해당 레벨에 적합한 렌더링 품질을 최적화하는 동시에 전반적인 장면 구조를 독립적으로 캡처한다. 

FLoD의 하위 레벨은 더 적고 더 큰 Gaussian을 사용하여 장면의 coarse한 구조를 재구성하는 반면, 상위 레벨은 더 많고 더 작은 Gaussian을 사용하여 디테일을 캡처하는 동시에 해당 레벨에 적합한 렌더링 품질을 최적화한다. 

사용자는 렌더링을 위해 FLoD에서 하나의 레벨을 선택할 수 있다. 또한 선택적 렌더링 방법을 통해 여러 레벨을 함께 사용하여 렌더링 효율성을 개선할 수 있다. 

### 1. Scale Constraint
$$l \in [1, L_\textrm{mas}]$$인 각 레벨 $l$에 대해 3D Gaussian의 하한으로 scale 제약 조건 $$s_\textrm{min}^{(l)}$$을 부과한다. $$s_\textrm{min}^{(l)}$$은 다음과 같이 정의된다. 

$$
\begin{equation}
s_\textrm{min}^{(l)} = \begin{cases}
\tau \times \rho^{1-l} & \quad \textrm{for} \; 1 \le l < L_\textrm{max} \\ 
0 & \quad \textrm{for} \; l = L_\textrm{max}
\end{cases}
\end{equation}
$$

$\tau$는 초기 scale 제약 조건이고 $\rho$는 scale factor이다. 레벨 $$L_\textrm{max}$$에서는 제약 조건 없이 가장 세밀한 디테일을 재구성할 수 있도록 scale 제약 조건은  0이다. 레벨 $l$에서 3D Gaussian scale은 다음과 같이 정의된다. 

$$
\begin{equation}
\mathbf{s}^{(l)} = e^{\mathbf{s}_\textrm{opt}} + s_\textrm{min}^{(l)}
\end{equation}
$$

여기서 $$\mathbf{s}_\textrm{opt}$$는 scale에 대한 학습 가능한 파라미터이고 $$s_\textrm{min}^{(l)}$$은 고정되어 있다. $$e^{\mathbf{s}_\textrm{opt}} > 0$$이기 때문에 $$\mathbf{s}^{(l)} > s_\textrm{min}^{(l)}$$이다. 

반면, 어떤 레벨에서도 Gaussian  크기에 대한 상한은 없다. 이를 통해 유연한 모델링이 가능하여 더 적고 더 큰 Gaussian으로 장면을 모델링할 수 있으며, 높은 레벨에서 많은 작은 Gaussian을 사용하는 중복을 피할 수 있다. 

### 2. Level-by-level Training
Coarse-to-fine 학습 프로세스를 통해 다음 레벨의 Gaussian이 완전히 학습된 이전 레벨의 Gaussian에 의해 초기화되도록 한다. 3DGS와 유사하게 레벨 1의 Gaussian은 SFM 포인트에서 초기화되며, 각 레벨은 특정 iteration동안 densification과 pruning을 수행하고 이후에는 densification과 pruning 없이 최적화된다. 

레벨 $l$에서 학습을 완료한 후 레벨 $l$의 최종 Gaussian으로 저장된다. 또한 레벨 $l$의 최종 Gaussian은 레벨 $l+1$의 Gaussian을 초기화하는 데 사용되며, scale은 다음과 같이 초기화된다. 

$$
\begin{equation}
\mathbf{s}_\textrm{opt} = \log (\mathbf{s}^{(l)} - s_\textrm{min}^{(l+1)})
\end{equation}
$$

이렇게 하면 $\mathbf{s}^{(l+1)} = \mathbf{s}^{(l)}$을 만족하도록 초기화되어 Gaussian의 scale이 유지된다. 

### 3. Overlap Pruning
저자들은 경험적으로 Gaussian 간의 과도한 중복이 아티팩트를 생성할 수 있음을 발견했다. 큰 중복이 있는 Gaussian을 제거하기 위해 세 nearest neighbor들의 평균 거리가 미리 정의된 threshold $$d_\textrm{OP}^{(l)}$$ 아래로 떨어지는 Gaussian을 제거한다. $$d_\textrm{OP}^{(l)}$$는 $$s_\textrm{min}^{(l)}$$의 절반으로 설정된다. 이 방법은 전체 메모리 공간을 줄이는 추가 이점이 있다. 

### 4. Selective Rendering
사용자는 가장 높은 레벨에서 작고 많은 Gaussian을 사용하여 고품질 렌더링을 얻을 수 있다. 그러나 이러한 렌더링은 느리거나 메모리 제한을 초과할 수도 있다. 따라서 여러 레벨의 3D Gaussian 세트 $$\{\mathbf{G}^{(l)} \; \vert \; l = 1, \ldots, L_\textrm{max}\}$$를 활용하여 더 빠르고 메모리 효율적으로 렌더링한다. 하나의 레벨에서 Gaussian을 렌더링하는 대신 장면의 여러 영역에 여러 레벨의 Gaussian을 할당하여 최소한의 품질 결함으로 렌더링 효율성을 개선한다. 

원하는 레벨 범위 $$L_\textrm{start}$$에서 $$L_\textrm{end}$$까지 Gaussian을 샘플링하여 선택적 렌더링을 위한 Gaussian 세트 $$\mathbf{G}_\textrm{sel}$$를 생성한다. 

$$
\begin{equation}
\mathbf{G}_\textrm{sel} = \bigcup_{l = L_\textrm{start}}^{L_\textrm{end}} \{ G^{(l)} \in \mathbf{G}^{(l)} \; \vert \; d_\textrm{proj}^{(l-1)} \ge d_{G^{(l)}} \ge d_\textrm{proj}^{(l)} \}
\end{equation}
$$

여기서 $$d_\textrm{proj}^{(l)}$$는 카메라와의 거리가 $d_{G^{(l)}}$인 Gaussian $G^{(l)}$의 포함을 결정하며, 다음과 같이 정의된다. 

$$
\begin{equation}
d_\textrm{proj}^{(l)} = \frac{s_\textrm{min}^{(l)}}{\gamma} \times f
\end{equation}
$$

($\gamma$: screensize threshold, $f$: 초점 거리)

$$d_\textrm{proj}^{(L_\textrm{end})} = 0$$, $$d_\textrm{proj}^{(L_\textrm{start}-1)} = \infty$$로 설정하여 $$L_\textrm{start}$$가 더 높은 레벨에서 아직 다루지 않은 장면의 나머지 더 먼 영역을 다루도록 한다. 

계산 복잡도를 줄이기 위해 거리 $$d_\textrm{proj}^{(l)}$$에 따라 Gaussian을 선택한다. 이 방법은 선택적 렌더링 중에 모든 레벨 $l$의 Gaussian을 $$s_\textrm{min}^{(l)}$$과 동일한 scale을 갖는 것으로 취급한다. 이는 Gaussian이 최적화할 수 있는 가장 작은 scale을 나타내기 때문이다. 이 방법은 각 Gaussian의 2D projection을 개별적으로 계산하고 모든 레벨에서 $\gamma$와 비교할 필요가 없어 계산적으로 더 효율적이다. 

Threshold $\gamma$와 레벨 범위 $$[L_\textrm{start}, L_\textrm{end}]$$는 특정 메모리 제한이나 원하는 렌더링 속도에 맞게 조정할 수 있다. 작은 threshold와 높은 레벨 범위는 메모리와 속도보다 디테일을 우선시하는 반면, 큰 threshold와 낮은 레벨 범위는 디테일을 희생하는 대신 메모리 사용을 줄이고 렌더링 속도를 높인다. 

### 5. Compatibility to Different Backbones
3D Gaussian에 3D scale 제약을 부과하는 FLoD는 다른 3DGS 기반 기술과 쉽게 통합할 수 있다. 저자들은 앵커 기반의 neural Gaussian을 활용하는 [Scaffold-GS](https://kimjy99.github.io/논문리뷰/scaffold-gs)에 FLoD를 통합하였다. Neural Gaussian에 점진적으로 감소하는 scale 제약을 적용하여 여러 레벨의 Scaffold-GS 세트를 생성하며, 마찬가지로 레벨별 학습을 통해 최적화된다. 

## Experiment
- 데이터셋: Tanks&Temples, Mip-NeRF360, DL3DV-10K
- 구현 디테일
  - GPU: NVIDIA RTX A5000 24GB 1개
  - $$L_\textrm{max}$$ = 5
  - $\tau$ = 0.2, $\rho$ = 4
  - densification 간격: 2000, 1000, 500, 500, 200
  - overlap pruning: 매 1000 iteration

### 1. Results and Evaluation
다음은 다른 방법들과 렌더링 성능을 비교한 결과이다. 

<center><img src='{{"/assets/img/flod/flod-fig3.PNG" | relative_url}}' width="100%"></center>
<span style="display: block; margin: 1px 0;"></span>
<center><img src='{{"/assets/img/flod/flod-table1.PNG" | relative_url}}' width="90%"></center>
<br>
다음은 [Octree-GS](https://arxiv.org/abs/2403.17898)와 단일 레벨 렌더링 결과를 비교한 것이다. 

<center><img src='{{"/assets/img/flod/flod-fig4.PNG" | relative_url}}' width="100%"></center>
<br>
다음은 최대 레벨 렌더링과 선택적 렌더링 결과를 비교한 것이다. 

<center><img src='{{"/assets/img/flod/flod-fig6.PNG" | relative_url}}' width="70%"></center>
<br>
다음은 $l = 3, 2, 1$만 렌더링한 결과를 Octree-GS와 비교한 것이다. 

<center><img src='{{"/assets/img/flod/flod-fig7.PNG" | relative_url}}' width="70%"></center>
<br>
다음은 MX250 GPU에서의 FPS와 Gaussian 수를 레벨에 따라 비교한 그래프이다. 

<center><img src='{{"/assets/img/flod/flod-fig8.PNG" | relative_url}}' width="80%"></center>
<br>
다음은 backbone 모델과 FLoD를 적용한 모델을 비교한 표이다. 

<center><img src='{{"/assets/img/flod/flod-table2.PNG" | relative_url}}' width="46%"></center>
<br>
다음은 Scaffold-GS에 FLoD를 적용한 결과이다. 

<center><img src='{{"/assets/img/flod/flod-fig5.PNG" | relative_url}}' width="100%"></center>

### 2. Ablation Study
다음은 scale 제약 조건에 대한 ablation 결과이다. 

<center><img src='{{"/assets/img/flod/flod-fig9.PNG" | relative_url}}' width="72%"></center>
<br>
다음은 레벨별 학습에 대한 ablation 결과이다. 

<center><img src='{{"/assets/img/flod/flod-fig10.PNG" | relative_url}}' width="70%"></center>
<br>
다음은 overlap pruning에 대한 ablation 결과이다. 

<center><img src='{{"/assets/img/flod/flod-fig11.PNG" | relative_url}}' width="90%"></center>
<span style="display: block; margin: 1px 0;"></span>
<center><img src='{{"/assets/img/flod/flod-table3.PNG" | relative_url}}' width="37%"></center>

## Limitation
FLoD를 적용한 모델은 backbone 모델보다 런타임 메모리를 적게 사용하지만 모든 레벨을 수용하기 위해 더 큰 디스크 저장 공간이 필요하다. 